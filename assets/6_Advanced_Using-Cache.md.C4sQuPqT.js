import{_ as a,c as n,o as s,ag as c}from"./chunks/framework.BRQrZDXk.js";const u=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"6_Advanced/Using-Cache.md","filePath":"6_Advanced/Using-Cache.md"}'),o={name:"6_Advanced/Using-Cache.md"};function t(i,e,p,l,r,h){return s(),n("div",null,e[0]||(e[0]=[c(`<h2 id="what-is-cache" tabindex="-1">What is Cache? <a class="header-anchor" href="#what-is-cache" aria-label="Permalink to &quot;What is Cache?&quot;">​</a></h2><p>Cache is a way of taking expensive values we&#39;ve computed and storing them in resident memory for a period of time. A good example is &quot;top books this week&quot; -- such a query likely won&#39;t change much if we re-run it multiple times a second, whereas doing so may have a significant (even untenable) consequence on CPU or the database. Therefore, we <code>cache</code> the computed value for some period of time (e.g. 1 hour).</p><h2 id="minimal-reference-example" tabindex="-1">Minimal Reference Example <a class="header-anchor" href="#minimal-reference-example" aria-label="Permalink to &quot;Minimal Reference Example&quot;">​</a></h2><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>from openlibrary.core import cache</span></span>
<span class="line"><span></span></span>
<span class="line"><span>def fibonacci(n):</span></span>
<span class="line"><span>    return (</span></span>
<span class="line"><span>        fibonacci(n - 1) + fibonacci(n - 2)</span></span>
<span class="line"><span>        if n &gt;= 1 </span></span>
<span class="line"><span>        else (1 if n &gt; 0 else 0)</span></span>
<span class="line"><span>    )</span></span>
<span class="line"><span></span></span>
<span class="line"><span>cached_fibonacci = cache.memcache_memoize(fibonacci, key_prefix=&#39;fib&#39;, timeout=60*5)</span></span></code></pre></div><h2 id="how-cache-lifecycle-works" tabindex="-1">How Cache Lifecycle Works <a class="header-anchor" href="#how-cache-lifecycle-works" aria-label="Permalink to &quot;How Cache Lifecycle Works&quot;">​</a></h2><p>When a function is cached and run for the first time, there is no value to retrieve from cache to return to the waiting patron, and so the lookup will fail. Therefore, since the patron is waiting on the value, it is computed on the main thread of the web application and saved in cache. The next time the cached version of the function is called, the value will be looked up in cache and returned to the patron <strong>unless</strong> the timeout expiration period has been reached, in which case the <strong>stale</strong> value from cache will be returned to the patron and the function will, in the background, be asynchronously re-run <strong>on a memcache thread</strong>. This way we can avoid a patron having to wait and be blocked on an expensive function being run.</p><h2 id="caching-web-ctx" tabindex="-1">Caching web.ctx <a class="header-anchor" href="#caching-web-ctx" aria-label="Permalink to &quot;Caching web.ctx&quot;">​</a></h2><p>Because of how memcache asynchronously recomputes functions on worker threads, outside the context of the main application, two important considerations follow:</p><ol><li>Privacy: Every patron&#39;s request will have different <code>web.ctx</code> objects with information unique and sensitive to their specific request(s) and so we want to be very careful not to cache these objects and leak their private information to other patrons.</li><li>Limited Access: Many request or application-specific objects, like the <code>web.ctx</code> object, are necessary for accessing things like the database but are not available from the context of memcached threads.</li></ol><p>In <a href="https://github.com/internetarchive/openlibrary/issues/10318#issuecomment-2598903078" target="_blank" rel="noreferrer">some cases</a>, the function you&#39;re caching will need access to the <code>web.ctx</code> object. To achieve this safely, your cached function should use <code>delegate.fakeload()</code> which will hydrate a minimal, <code>web.ctx</code> object that can be safely used within the context of the cached function. In the following example, our cached function presumably calls a function that needs access to the <code>lang</code> property of the <code>web.ctx</code> object. Since <code>web.ctx</code> is not available in/from the memcache worker thread, we can use <code>delegate.fakeload()</code> to initiate a safe <code>web.ctx</code> object and then we can inject our desired <code>lang</code> value into the hydrated object.</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def my_cachable_function(web_ctx_lang):</span></span>
<span class="line"><span>if &#39;env&#39; not in web.ctx:</span></span>
<span class="line"><span>    delegate.fakeload()</span></span>
<span class="line"><span>    web.ctx.lang = web_ctx_lang</span></span></code></pre></div><h2 id="walkthrough" tabindex="-1">Walkthrough <a class="header-anchor" href="#walkthrough" aria-label="Permalink to &quot;Walkthrough&quot;">​</a></h2><p>Let&#39;s assume you have an expensive function like fibonacci:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>def fibonacci(n):</span></span>
<span class="line"><span>    return (</span></span>
<span class="line"><span>        fibonacci(n - 1) + fibonacci(n - 2)</span></span>
<span class="line"><span>        if n &gt;= 1 </span></span>
<span class="line"><span>        else (1 if n &gt; 0 else 0)</span></span>
<span class="line"><span>    )</span></span></code></pre></div><p>The <code>openlibrary.core.cache.memcache_memoize</code> method is used as a decorator to return a cache-enabled version of <code>fibonacci</code> (we&#39;ll call <code>cached_fibonacci</code>) which, when called, first checks whether a recent enough, precomputed value exists in cache for the given input arguments before proceeding to call <code>fibonacci</code>. For instance, if we call <code>cached_fibonacci(4)</code>, <code>memcache_memoize</code> will look in cache&#39;s memory for a record corresponding to the function <code>fibonacci</code> with corresponding argument <code>4</code> to see if a corresponding pre-computed value exists and if so, will return it. If no such value exists or the value in cache is too old, <code>fibonacci</code> will then be called and the corresponding value will be inserted or updated within cache under the function <code>fibonacci</code> and the argument <code>4</code> with an updated timestamp to be used/evaluated by the next lookup.</p><p>In reality, the parameter <code>key_prefix</code> to <code>memcache_memoize</code> (and not the function&#39;s name) is used in conjunction with the input parameters to the cached function in order to computer the cache key. For instance, a real example may look like this:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>cached_fibonacci = cache.memcache_memoize(fibonacci, key_prefix=&#39;fib&#39;, timeout=60*5)</span></span></code></pre></div><p>This call to <code>memcache_memoize</code> returns a cache-enabled version of <code>fibonacci</code> that will cache each computed value for 5 minutes using the key <code>fib</code> in union with whatever <code>args</code> and <code>kwargs</code> get passed into <code>fibonacci</code>. In practice, for our example, we might expect the cache <code>key</code> of <code>cached_fibonacci</code> to look like <code>fib-4</code>.</p><h2 id="reference-code" tabindex="-1">Reference Code <a class="header-anchor" href="#reference-code" aria-label="Permalink to &quot;Reference Code&quot;">​</a></h2><p>See <a href="https://github.com/internetarchive/openlibrary/blob/3bad3325e1392102db485dea34db67a186af2dcf/openlibrary/plugins/openlibrary/home.py#L181-L208" target="_blank" rel="noreferrer">generic_carousel</a>&#39;s use of <code>cache.memcache_memoize</code> in <code>plugins/openlibrary/home.py</code> to cache the any result computed by <code>get_ia_carousel_books</code> function for 2 minutes.</p><h2 id="how-to-test-cache" tabindex="-1">How to test cache <a class="header-anchor" href="#how-to-test-cache" aria-label="Permalink to &quot;How to test cache&quot;">​</a></h2><p>First, go into the <code>web</code> docker container where you have access to python and openlibrary:</p><p><code>docker compose exec web python</code></p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>import time</span></span>
<span class="line"><span>import web</span></span>
<span class="line"><span>import infogami</span></span>
<span class="line"><span>from openlibrary.config import load_config</span></span>
<span class="line"><span>load_config(&#39;conf/openlibrary.yml&#39;) # for local dev</span></span>
<span class="line"><span># load_config(&#39;/olsystem/etc/openlibrary.yml&#39;) # for prod</span></span>
<span class="line"><span>infogami._setup()</span></span>
<span class="line"><span>from infogami import config</span></span>
<span class="line"><span>from openlibrary.core import cache</span></span>
<span class="line"><span></span></span>
<span class="line"><span>def my_function(arg1, arg2, kwarg1=&quot;a&quot;, &quot;kwarg2=&quot;b&quot;):</span></span>
<span class="line"><span>    return (arg1, arg2, kwarg1, kwarg2)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Create a cached version of \`my_function\`</span></span>
<span class="line"><span>my_cached_function = cache.memcache_memoize(my_function, key_prefix=&#39;myfunc&#39;, timeout=60*5)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># An example call:</span></span>
<span class="line"><span># Calling \`my_cached_function\` will first check cache to see if a pre-computed value already exists.</span></span>
<span class="line"><span># It does so by first computing a key based on the \`key_prefix\`  a </span></span>
<span class="line"><span></span></span>
<span class="line"><span> to the cache that looks something like &quot;myfunc-arg1-arg2-kwarg1-kwarg2&quot;</span></span>
<span class="line"><span># and save its value as well as the timestamp for when it was computed.</span></span>
<span class="line"><span># The next time we call it, the cache system will check the time to see whether to return</span></span>
<span class="line"><span># the cached value or whether to call \`my_function\` again and update the value in cache.</span></span>
<span class="line"><span>my_cached_function(&#39;arg1&#39;, &#39;arg2&#39;, a=2, b=3)</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Sometimes we may manually want to overwrite a function&#39;s cached value for a key:</span></span>
<span class="line"><span># memcache_set takes a list of args and kwargs (i.e. the inputs for \`my_function\`) and uses them to create</span></span>
<span class="line"><span># a cache key like &quot;myfunc-arg1-arg2-kwarg1-kwarg2&quot; which is what we use to fetch the function&#39;s pre-computed</span></span>
<span class="line"><span># value from cache.</span></span>
<span class="line"><span>my_cached_function.memcache_set([&#39;arg1&#39;, &#39;arg2&#39;], {&#39;a&#39;: 2, &#39;b&#39;: 3}, &#39;THIS IS MY NEW VALUE&#39;, time.time())</span></span>
<span class="line"><span></span></span>
<span class="line"><span># Similarly, we can update it </span></span>
<span class="line"><span>my_cached_function.memcache_get([&#39;arg1&#39;, &#39;arg2&#39;], {&#39;a&#39;: 2, &#39;b&#39;: 3})</span></span></code></pre></div>`,24)]))}const m=a(o,[["render",t]]);export{u as __pageData,m as default};
